# 高级分布式系统
简介：一些通过通信网络交流连接的自主处理器。分布式系统是**若干独立自主计算机**的集合（硬件），这些计算机对于用户来说像是**单个耦合**系统（软件）——用户或者应用程序感觉系统是一个系统。

## CH-1

特性：
- 无共享物理时钟
- 无共享内存
- 地理上分隔的
- 自主性（计算节点硬件或者软件进程是独立的）与异构性

各软件组件之间的关系（从上到下）：
分布式应用-分布式软件（中间件库）-操作系统和网络协议栈（应用层
传输层、网络层和数据链路层）

分布式系统的设计动机：
1. inherently distributed computation
2. 资源共享：多节点共享硬件、数据
3. 访问远程资源：跨网络访问资源
4. 提高性能/性价比：廉价节点集群实现高性能
5. 可靠性与可拓展性

并行系统：
1. 多处理器系统（直接访问共享内存，UMA model）
   - 互联网络：总线、多级交换机
2. 多计算机并行系统（无需直接访问共享内存，NUMA model）
   - 常用总线、环、mesh（无线网格网络）
3. 阵列处理器

UMA和NUMA（uniform memory access）
- uma 处理器和内存分离，通过内联网络实现对内存的共享，特点就是所有处理器访问内存的时间一致
- numa 处理器和内存绑定 节点间经过互连网络通信

OmegaNetwork

叽里咕噜的不知道说啥呢。反正就是n个处理器，n个内存；log2n个阶段，n/2个2*2容量的交换机通过互联函数形成某个拓扑结构。

Flynn’sTaxonomy 弗林分类法

分类及说明
- SISD（单指令流单数据流）
定义：单一指令流控制单一处理单元，处理单一数据流。
对应：传统串行计算机（如早期个人电脑）。
- SIMD（单指令流多数据流）
定义：单一指令流控制多个处理单元，同时处理多组数据流。
适用场景：科学计算、大型数组运算。
实例：向量处理器、脉动阵列、Pentium/SSE 指令集、DSP 芯片。
- MISD（多指令流单数据流）
定义：多个指令流控制不同处理单元，共同处理同一数据流。
实例：可视化场景（实际应用较少）。
- MIMD（多指令流多数据流）
定义：多个指令流分别控制不同处理单元，并行处理多组数据流。
适用场景：分布式系统、绝大多数并行系统（是当前主流并行架构）。

并行系统术语

- **耦合性（Coupling）**
定义：硬件 / 软件模块（如操作系统、中间件）之间的依赖 / 绑定程度。
解读：决定了系统的紧 / 松耦合特性（如 UMA 是紧耦合，NUMA 是松耦合）。
- **并行度（Parallelism）**
定义：T(1)/T(n)
（单处理单元耗时与 n 个处理单元耗时的比值）。
解读：由程序与系统共同决定，反映并行加速效果。
- 程序并发性（Concurrency of a program）
定义：衡量程序的有效 CPU 时间与同步等待时间的比例。
解读：并发性越高，CPU 利用率越高。
- 程序粒度（Granularity of a program）
定义：计算量与通信量的比值。
解读：细粒度程序适合紧耦合系统（通信延迟低），粗粒度程序适合松耦合系统。

Message-Passing vs. Shared Memory

消息传递与共享内存
- 基于共享内存模拟消息传递（Emulating MP over SM）：将共享地址空间分区，每个有专用的信箱。用内存的写/读来模拟消息的发送/接收
- 基于消息传递模拟共享内存（Emulating SM over MP）：将每个共享对象抽象为独立进程。实现方式：
  - 写共享对象：向该对象的拥有进程发送写消息；
  - 读共享对象：向该对象的拥有进程发送查询消息。

通信原语分类
- 同步（发/收）
  - 发送接收之前需要握手
  - 当接收完成发送才完成
  - 当数据拷贝到缓冲区接收才完成
- 异步（发）
  - 发送方当数据拷贝出用户缓冲区后，立即返回进程
- Blocking（send/ receive ）and Nonblocking（send/ receive ） 阻塞与非阻塞通信原语
  - 原语（无论 sync or async）处理完成后，控制权才返回调用进程
  - 调用后控制权立即返回进程，无需等待操作完成；发送：甚至在数据从用户缓冲区拷贝完成前就返回；接收：甚至在数据从发送方到达前就返回。

- Non-blocking Primitive 非阻塞原语的例子：当发起一个非阻塞的发送请求的时候，会返回一个$handle_k$句柄，然后在发送请求发出后，cpu可以去干别的事，直到你需要确认数据是否发送成功。确认的方式有持续检查（轮询）和发起等待（wait）两种，wait操作是阻塞的直到它等待的句柄之一被发布（实际上wait的常用的实现方法是基于硬件中断，除了一些HPC场景，它会把进程加入到一个等待名单中然后阻塞他，直到某个句柄发布然后检查下名单，将在等待对应句柄完成的进程ready）。

经典图片——阻塞/非阻塞；同步/异步；发送/接收原语
![alt text](image.png)
- 双横线 (=)：表示进程处于 Blocked（阻塞） 状态，暂停运行，什么都干不了。
- 单横线：表示进程处于 Running（运行） 状态，正在执行代码。
- 粗黑条：表示数据正在从用户缓冲区 复制 (Copy) 到内核缓冲区（或反之）的时间。
- Wait (W)：检查之前的非阻塞操作是否完成。

1. 阻塞同步发送：发送后阻塞，只有确定接收方接收完了，才解开阻塞
2. 非阻塞同步发送：发送后不阻塞，但是因为是同步的，还是要调用wait知道有没有接收完，接收完后才算发送完成。
3. 阻塞异步发送：进程仍会阻塞，但只阻塞到数据拷贝到本地内核缓冲区为止，也就是一旦把数据交给操作系统就算发送完成了
4. 非阻塞异步发送:调用完发送后函数立即返回。PS：系统只是记下了“你要发数据”这个请求，连数据拷贝都没做完，你就继续往下跑代码了。数据拷贝是在后台（由 DMA 或内核线程）默默进行的。当你需要重用你的数据缓冲区时，调用W来确认。

Asynchronous Executions; Mesage-passing System

异步执行基于一些最坏的情况考虑：
1. 不存在同步的处理器（处理器速率不一样），没有统一时钟且时钟的漂移无法预测（即使你在开始互相之间对准了，后续误差依旧无法预测）
2. 消息延迟有限但无上限 (Message delays are finite but unbounded)，消息不会丢（除非信道故障），但是你不知道它什么时候送达
3. 处理速度无上限。就是说我们不知道计算机处理一行代码要多久，可能在某个地方卡住了（硬盘什么的）要很久，也可能马上就好
